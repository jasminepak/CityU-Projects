{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"THA - FOUR_PAK KA YEE_55692027.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPbFJ3Ut5Hh+5svaSwYo3Cr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"NgHmCvZhT-Za"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"7_yI9IVaUACf"},"source":["# Url for notebook:\n","\n","https://colab.research.google.com/drive/1rVFOAmzAP3WsgxpGZcC1KhmH6vaLGGkF?usp=sharing\n","\n","\n","My Email: l175252973@gmail.com<BR>\n","My Name: PAK KA YEE<br>\n","My SID: 55692027"]},{"cell_type":"markdown","metadata":{"id":"MTbFONzNUwEZ"},"source":["#Question 1 \n","Build a python code to verify the solution of the backward path of the THA-THREE #3"]},{"cell_type":"markdown","metadata":{"id":"o7cNjyfOsHQH"},"source":["### THA-THREE #3\n","Compute the updated values of filter weights after backpropagation of the following problem -- 3x3 input matrix, 2x2 filter, stride 1, no padding, flatten it and use it as input connecting to a two-neuron layer, then pass the results to a softmax binary classification of two neurons.<br>\n","3a) (0.5%) What is the values of the <b>output</b> at <u>the end of the forward path</u><br>\n","3b) (1.5%) What are the <b>updated values</b> of <u>the weight</u> and <u>bias after backpropagation</u><br>\n","\n","### Python code\n"]},{"cell_type":"code","metadata":{"id":"279kZgBKv9uk","executionInfo":{"status":"ok","timestamp":1616694232353,"user_tz":-480,"elapsed":2774,"user":{"displayName":"白嘉仪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ncAmpCyCSwzNY-iDenfxgZWzZjwm0MDZp12Q8A=s64","userId":"14826254854338762366"}}},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.python.keras.applications.resnet import ResNet, stack1\n","\n","\n","def sigmoid(z):\n","  return 1/(1-np.exp(-z))\n","\n","def d_sigmoid(z):\n","  return z*(1-x)\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nUUlH3qkF1Gf","executionInfo":{"status":"ok","timestamp":1616697494306,"user_tz":-480,"elapsed":1027,"user":{"displayName":"白嘉仪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ncAmpCyCSwzNY-iDenfxgZWzZjwm0MDZp12Q8A=s64","userId":"14826254854338762366"}},"outputId":"e030aac7-2241-415f-d2e6-f1e3769a1690"},"source":["input = np.array([\n","                  [1, 0, 1],\n","                  [0, 1, 0],\n","                  [1, 0, 1]\n","])\n","filter = np.array([\n","                   [0.9, 0.1],\n","                   [0.1, 0.9]\n","])\n","\n","w1 = 0.1\n","w2 = 0.2\n","w3 = 0.3\n","w4 = 0.4\n","w5 = 0.5\n","w6 = 0.6\n","w7 = 0.7\n","w8 = 0.8\n","\n","wh1 = 0.1\n","wh2 = 0.2\n","wh3 = 0.3\n","wh4 = 0.4\n","wh5 = 0.5\n","wh6 = 0.6\n","wh7 = 0.7\n","wh8 = 0.8\n","\n","b1 = 0.1\n","b2 = 0.2\n","b3 = 0.3\n","\n","\n","bh1 = 0.2\n","bh2 = 0.2\n","\n","#learning rate eta\n","eta = 0.5\n","\n","y1 = 1\n","y2 = 0\n","\n","def im2col(input, filter):\n","\n","# flatten input and filter\n","    k = filter.shape[0]\n","\n","    flatten_input = []\n","    for i in range(input.shape[0] - k + 1):\n","        for j in range(input[0].shape[0] - k + 1):\n","            flatten_input.append(input[i:i+k, j: j+k].flatten())\n","\n","    flatten_input = np.array(flatten_input)\n","\n","    flatten_filter = filter.flatten()\n","\n","# flattened feature\n","    flatten_feature = (flatten_input @ flatten_filter) + b1\n","\n","# resahpe the flattened feature\n","    return flatten_feature.reshape((2,2))\n","\n","c = im2col(input, filter)\n","\n","\n","h1 = np.sum(c * np.array([[w1, w2,], [w3, w4]])) + b2\n","h2 = np.sum(c * np.array([[w5, w6,], [w7, w8]])) + b2\n","\n","\n","# ReLu\n","h1 = tf.nn.relu(h1)\n","h2 = tf.nn.relu(h2)\n","relu = np.array([h1, h2])\n","\n","# calulate softmax\n","sm_o1 = np.sum(relu*np.array([w1, w2])) + b3 \n","sm_o2 = np.sum(relu*np.array([w3, w4])) + b3 \n","o1 = (np.exp(sm_o1)) / (np.exp(sm_o1) + np.exp(sm_o2))\n","o2 = (np.exp(sm_o2)) / (np.exp(sm_o1) + np.exp(sm_o2))\n","\n","# calulate the loss\n","l1 = o1 - y1\n","l2 = o2 - y2\n","\n","# calculate the gradient of woi: i = 1 ~ 4\n","# loss1\n","d_wo1 = l1 * h1\n","d_wo2 = l1 * h2\n","d_bo1 = l1\n","d_h11 = l1 * w1\n","d_h21 = l1 * w2\n","\n","wo1_plus = w1 - eta * d_wo1\n","wo2_plus = w2 - eta * d_wo2\n","bo1_plus = b3 - eta * d_bo1\n","\n","# loss2\n","d_wo3 = l2 * h1\n","d_wo4 = l2 * h2\n","d_bo2 = l2\n","d_h12 = l2 * w3\n","d_h22 = l2 * w4\n","\n","wo3_plus = w3 - eta * d_wo3\n","wo4_plus = w4 - eta * d_wo4\n","bo2_plus = b3 - eta * d_bo2\n","\n","bo_plus = (bo1_plus + bo2_plus) / 2\n","\n","print('wo1+: ' + \"%0.8f\" % wo1_plus)\n","print('wo2+: ' + \"%0.8f\" % wo2_plus)\n","print('bo1+: ' + \"%0.8f\" % bo1_plus)\n","print('dh11: ' + \"%0.8f\" % d_h11)\n","print('dh21: ' + \"%0.8f\" % d_h21)\n","print('wo3+: ' + \"%0.8f\" % wo3_plus)\n","print('wo4+: ' + \"%0.8f\" % wo4_plus)\n","print('bo2+: ' + \"%0.8f\" % bo2_plus)\n","print('dh12: ' + \"%0.8f\" % d_h12)\n","print('dh22: ' + \"%0.8f\" % d_h22)\n","print('bo+: ' + \"%0.8f\" % bo_plus)\n","print('=================================')\n","\n","# update wh1+ ~ wh8+, bh1+, bh2+\n","d_h1 = d_h11 + d_h12\n","d_h2 = d_h21 + d_h22\n","\n","\n","print('d_h1: ' + \"%0.8f\" % d_h1)\n","print('d_h2: ' + \"%0.8f\" % d_h2)\n","\n","dwh1 = c[0][0] * d_h1\n","dwh2 = c[1][0] * d_h1\n","dwh3 = c[0][1] * d_h1\n","dwh4 = c[1][1] * d_h1\n","dwh5 = c[0][0] * d_h1\n","dwh6 = c[1][0] * d_h1\n","dwh7 = c[0][1] * d_h1\n","dwh8 = c[1][1] * d_h1\n","dbh1 = d_h1\n","dbh2 = d_h2\n","\n","print('wh1+: ' + \"%0.8f\" % (wh1 - eta * dwh1))\n","print('wh2+: ' + \"%0.8f\" % (wh2 - eta * dwh2))\n","print('wh3+: ' + \"%0.8f\" % (wh3 - eta * dwh3))\n","print('wh4+: ' + \"%0.8f\" % (wh4 - eta * dwh4))\n","print('wh5+: ' + \"%0.8f\" % (wh5 - eta * dwh5))\n","print('wh6+: ' + \"%0.8f\" % (wh6 - eta * dwh6))\n","print('wh7+: ' + \"%0.8f\" % (wh7 - eta * dwh7))\n","print('wh8+: ' + \"%0.8f\" % (wh8 - eta * dwh8))\n","print('bh1+: ' + \"%0.8f\" % (bh1 - eta * dbh1))\n","print('bh2+: ' + \"%0.8f\" % (bh2 - eta * dbh2))\n","print(\"=================================\")\n","\n","dC1h1 = wh1 * d_h1\n","dC2h1 = wh2 * d_h1\n","dC3h1 = wh3 * d_h1\n","dC4h1 = wh4 * d_h1\n","dC1h2 = wh5 * d_h2\n","dC2h2 = wh6 * d_h2\n","dC3h2 = wh7 * d_h2\n","dC4h2 = wh8 * d_h2\n","\n","print('dC1h1: ' + \"%0.8f\" % dC1h1)\n","print('dC2h1: ' + \"%0.8f\" % dC2h1)\n","print('dC3h1: ' + \"%0.8f\" % dC3h1)\n","print('dC4h1: ' + \"%0.8f\" % dC4h1)\n","print('dC1h2: ' + \"%0.8f\" % dC1h2)\n","print('dC2h2: ' + \"%0.8f\" % dC2h2)\n","print('dC3h2: ' + \"%0.8f\" % dC3h2)\n","print('dC4h2: ' + \"%0.8f\" % dC4h2)\n","print(\"=================================\")\n","\n","dC1 = dC1h1 + dC1h2\n","dC2 = dC2h1 + dC2h2\n","dC3 = dC3h1 + dC3h2\n","dC4 = dC4h1 + dC4h2\n","print('dC1: ' + \"%0.8f\" % dC1)\n","print('dC2: ' + \"%0.8f\" % dC2)\n","print('dC3: ' + \"%0.8f\" % dC3)\n","print('dC4: ' + \"%0.8f\" % dC4)\n","print(\"=================================\")\n","print('The dL/dF matrix is: ')\n","\n","# dL/dF\n","d_filter = np.array([\n","                   [dC1, dC2],\n","                   [dC3, dC4]\n","])\n","\n","def im2col(input, d_filter):\n","\n","# flatten input and d_filter\n","    k = d_filter.shape[0]\n","\n","    flatten_input = []\n","    for i in range(input.shape[0] - k + 1):\n","        for j in range(input[0].shape[0] - k + 1):\n","            flatten_input.append(input[i:i+k, j: j+k].flatten())\n","\n","    flatten_input = np.array(flatten_input)\n","\n","    flatten_filter = d_filter.flatten()\n","\n","# flattened feature\n","    flatten_feature = (flatten_input @ flatten_filter)\n","\n","# resahpe the flattened feature\n","    return flatten_feature.reshape((2,2))\n","\n","f= im2col(input, d_filter)\n","print(f)\n","\n","print('db: ' + \"%0.8f\" % (dC1 + dC2 + dC3 + dC4))\n","print('b1+: ' + \"%0.8f\" % (b1 - eta * (dC1 + dC2 + dC3 + dC4)))\n","\n","print(filter - eta * f)\n","\n","\n","\n","\n","\n"],"execution_count":44,"outputs":[{"output_type":"stream","text":["wo1+: 0.55835510\n","wo2+: 1.27889738\n","bo1+: 0.65258084\n","dh11: -0.07051617\n","dh21: -0.14103234\n","wo3+: -0.15835510\n","wo4+: -0.67889738\n","bo2+: -0.05258084\n","dh12: 0.21154851\n","dh22: 0.28206467\n","bo+: 0.30000000\n","=================================\n","d_h1: 0.14103234\n","d_h2: 0.14103234\n","wh1+: -0.03398072\n","wh2+: 0.17884515\n","wh3+: 0.27884515\n","wh4+: 0.26601928\n","wh5+: 0.36601928\n","wh6+: 0.57884515\n","wh7+: 0.67884515\n","wh8+: 0.66601928\n","bh1+: 0.12948383\n","bh2+: 0.12948383\n","=================================\n","dC1h1: 0.01410323\n","dC2h1: 0.02820647\n","dC3h1: 0.04230970\n","dC4h1: 0.05641293\n","dC1h2: 0.07051617\n","dC2h2: 0.08461940\n","dC3h2: 0.09872264\n","dC4h2: 0.11282587\n","=================================\n","dC1: 0.08461940\n","dC2: 0.11282587\n","dC3: 0.14103234\n","dC4: 0.16923880\n","=================================\n","The dL/dF matrix is: \n","[[0.25385821 0.25385821]\n"," [0.25385821 0.25385821]]\n","db: 0.50771641\n","b1+: -0.15385821\n","[[ 0.7730709 -0.0269291]\n"," [-0.0269291  0.7730709]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"L4YbZuLariuJ"},"source":["###Question #2 \n","Based on the TensorFlow tutorial for CNN from https://www.tensorflow.org/tutorials/images/cnn, add tensorboard functions to the code. Proceed to Generate a list of the results for 3 different values of learning rate, epoch, dropout, and batch size. Present your results in a table and give an optimal combination of such hyperparameters. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mUUJHnW2h1GS","executionInfo":{"status":"ok","timestamp":1616728544518,"user_tz":-480,"elapsed":847,"user":{"displayName":"白嘉仪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ncAmpCyCSwzNY-iDenfxgZWzZjwm0MDZp12Q8A=s64","userId":"14826254854338762366"}},"outputId":"af24a03d-20f7-4768-c5bc-9863c9e5c4df"},"source":["%load_ext tensorboard"],"execution_count":7,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"eFihwBeEfia1","executionInfo":{"status":"error","timestamp":1616729908543,"user_tz":-480,"elapsed":47605,"user":{"displayName":"白嘉仪","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh_ncAmpCyCSwzNY-iDenfxgZWzZjwm0MDZp12Q8A=s64","userId":"14826254854338762366"}},"outputId":"7ded181b-7586-4f19-e3ca-62a67be8f6a1"},"source":["\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import tensorflow as tf\n","from itertools import product\n","(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n","\n","\n","train_images, test_images = train_images / 255.0, test_images / 255.0\n","class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n","\n","\n","learning_rates = [0.1, 0.01, 0.001]\n","epochs = [1, 5 ,10]\n","dropout_rates = [0.2, 0.5, 0.8]\n","batch_sizes = [32, 64, 128]\n","\n","performance_df = pd.DataFrame(columns=['learning_rate', 'epoch', 'dropout', 'batch_size'])\n","\n","for params in product(\n","    learning_rates, epochs, dropout_rates, batch_sizes\n","):\n","    lr, ep, dr, bs = params\n","    model = models.Sequential()\n","    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","    model.add(layers.MaxPooling2D((2, 2)))\n","    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","    model.add(layers.Dropout(dr))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(64, activation='relu'))\n","    model.add(layers.Dense(10))\n","    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n","    model.compile(optimizer=opt,\n","                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                  metrics=['accuracy'])\n","\n","    log_dir = f\"logs/fit/lr{lr}ep{ep}dr{dr}bs{bs}\"\n","    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","\n","    history = model.fit(train_images, train_labels, epochs=ep,\n","                        batch_size=bs,\n","                        validation_data=(test_images, test_labels),\n","                        callbacks=[tensorboard_callback])\n","    train_loss, train_acc = model.evaluate(train_images, train_labels, verbose=2)\n","    test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n","    performance_df = performance_df.append({\n","        'learning_rate': lr,\n","        'epoch': ep,\n","        'dropout': dr,\n","        'batch_size': bs,\n","        'train_loss': train_loss,\n","        'train_accuracy': train_acc,\n","        'test_loss': test_loss,\n","        'test_accuracy': test_acc,\n","    }, ignore_index =True)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["1563/1563 [==============================] - 71s 45ms/step - loss: 41.4255 - accuracy: 0.0983 - val_loss: 2.3134 - val_accuracy: 0.1000\n","1563/1563 - 18s - loss: 2.3134 - accuracy: 0.1000\n","313/313 - 4s - loss: 2.3134 - accuracy: 0.1000\n","782/782 [==============================] - 67s 85ms/step - loss: 133.4425 - accuracy: 0.0991 - val_loss: 2.3101 - val_accuracy: 0.1000\n","1563/1563 - 18s - loss: 2.3101 - accuracy: 0.1000\n","313/313 - 3s - loss: 2.3101 - accuracy: 0.1000\n","391/391 [==============================] - 61s 154ms/step - loss: 128.9045 - accuracy: 0.0988 - val_loss: 2.3040 - val_accuracy: 0.1000\n","1563/1563 - 18s - loss: 2.3040 - accuracy: 0.1000\n","313/313 - 4s - loss: 2.3040 - accuracy: 0.1000\n","1563/1563 [==============================] - 71s 45ms/step - loss: 38.6325 - accuracy: 0.1027 - val_loss: 2.3099 - val_accuracy: 0.1000\n","1563/1563 - 18s - loss: 2.3099 - accuracy: 0.1000\n","313/313 - 4s - loss: 2.3099 - accuracy: 0.1000\n","782/782 [==============================] - 64s 81ms/step - loss: 38.8663 - accuracy: 0.1000 - val_loss: 2.3106 - val_accuracy: 0.1000\n","1563/1563 - 17s - loss: 2.3106 - accuracy: 0.1000\n","313/313 - 4s - loss: 2.3106 - accuracy: 0.1000\n","391/391 [==============================] - 58s 148ms/step - loss: 53.6437 - accuracy: 0.0994 - val_loss: 2.3060 - val_accuracy: 0.1000\n","1563/1563 - 17s - loss: 2.3060 - accuracy: 0.1000\n","313/313 - 3s - loss: 2.3060 - accuracy: 0.1000\n","1563/1563 [==============================] - 70s 44ms/step - loss: 16.3280 - accuracy: 0.1007 - val_loss: 2.3101 - val_accuracy: 0.1000\n","1563/1563 - 18s - loss: 2.3101 - accuracy: 0.1000\n","313/313 - 4s - loss: 2.3101 - accuracy: 0.1000\n","782/782 [==============================] - 65s 83ms/step - loss: 37.7535 - accuracy: 0.0992 - val_loss: 2.3095 - val_accuracy: 0.1000\n","1563/1563 - 18s - loss: 2.3095 - accuracy: 0.1000\n","313/313 - 4s - loss: 2.3095 - accuracy: 0.1000\n","391/391 [==============================] - 62s 158ms/step - loss: 93.8813 - accuracy: 0.1036 - val_loss: 2.3055 - val_accuracy: 0.1000\n","1563/1563 - 19s - loss: 2.3055 - accuracy: 0.1000\n","313/313 - 4s - loss: 2.3055 - accuracy: 0.1000\n","Epoch 1/5\n","1563/1563 [==============================] - 73s 46ms/step - loss: 44.3398 - accuracy: 0.0991 - val_loss: 2.3148 - val_accuracy: 0.1000\n","Epoch 2/5\n","1563/1563 [==============================] - 71s 46ms/step - loss: 2.3154 - accuracy: 0.1009 - val_loss: 2.3100 - val_accuracy: 0.1000\n","Epoch 3/5\n","1563/1563 [==============================] - 72s 46ms/step - loss: 2.3160 - accuracy: 0.0963 - val_loss: 2.3125 - val_accuracy: 0.1000\n","Epoch 4/5\n","1563/1563 [==============================] - 71s 46ms/step - loss: 2.3157 - accuracy: 0.0994 - val_loss: 2.3049 - val_accuracy: 0.1000\n","Epoch 5/5\n","1563/1563 [==============================] - 70s 44ms/step - loss: 2.3155 - accuracy: 0.0996 - val_loss: 2.3201 - val_accuracy: 0.1000\n","1563/1563 - 18s - loss: 2.3201 - accuracy: 0.1000\n","313/313 - 4s - loss: 2.3201 - accuracy: 0.1000\n","Epoch 1/5\n","782/782 [==============================] - 67s 84ms/step - loss: 98.7696 - accuracy: 0.1004 - val_loss: 2.3087 - val_accuracy: 0.1000\n","Epoch 2/5\n","782/782 [==============================] - 70s 89ms/step - loss: 2.3109 - accuracy: 0.0964 - val_loss: 2.3144 - val_accuracy: 0.1000\n","Epoch 3/5\n","516/782 [==================>...........] - ETA: 22s - loss: 2.3162 - accuracy: 0.0994"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-d3ffac3bb291>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                         callbacks=[tensorboard_callback])\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"daqyUgF3nddz"},"source":["%tensorboard --logdir logs/fit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQotgo_9nprG"},"source":["performance_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HJoLZogenr-2"},"source":["plt.scatter(performance_df.learning_rate, performance_df.train_accuracy, c='red', alpha=0.5)\n","plt.scatter(performance_df.learning_rate, performance_df.test_accuracy, c='blue', alpha=0.5)\n","plt.title('Learning Rate to Performance')\n","plt.show()\n","\n","plt.scatter(performance_df.epochs, performance_df.train_accuracy, c='red', alpha=0.5)\n","plt.scatter(performance_df.epochs, performance_df.test_accuracy, c='blue', alpha=0.5)\n","plt.title('Epoch to Performance')\n","plt.show()\n","\n","plt.scatter(performance_df.dropout, performance_df.train_accuracy, c='red', alpha=0.5)\n","plt.scatter(performance_df.dropout, performance_df.test_accuracy, c='blue', alpha=0.5)\n","plt.title('Dropout to Performance')\n","plt.show()\n","\n","plt.scatter(performance_df.batch_size, performance_df.train_accuracy, c='red', alpha=0.5)\n","plt.scatter(performance_df.batch_size, performance_df.test_accuracy, c='blue', alpha=0.5)\n","plt.title('Batch Size to Performance')\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0RbWLBDCnyl8"},"source":["When Learning rate is smaller,Epoch is higher and Dropout is 0.5, the Model performance becomes better. Batch size does not seem to affect the model performance, it only helps the model train faster."]},{"cell_type":"markdown","metadata":{"id":"fYGgdt4pr9KT"},"source":["###Question #3\n","Download and run the https://keras.io/examples/vision/oxford_pets_image_segmentation/ and explain what it does."]}]}